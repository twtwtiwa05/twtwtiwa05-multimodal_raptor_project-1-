"""
KTDB GTFS í‘œì¤€ ê¸°ë°˜ ì™„ì „í•œ êµí†µ ë°ì´í„° ë¡œë”
- GTFS ê°œë³„ íŒŒì¼ (agency, stops, routes, trips, stop_times, calendar)
- ë„ë¡œë§ SHP íŒŒì¼ 
- ë°ì´í„° í†µí•© ë° ë¶„ì„
"""

import geopandas as gpd
import pandas as pd
import numpy as np
from pathlib import Path
import zipfile
import warnings
from typing import Dict, Tuple, Optional, List
import os
import time
from datetime import datetime


warnings.filterwarnings('ignore')

class KTDBGTFSLoader:
    """KTDB GTFS í‘œì¤€ ê¸°ë°˜ êµí†µ ë°ì´í„° ë¡œë”"""
    
    def __init__(self, road_data_path: str, gtfs_data_path: str):
        self.road_data_path = Path(road_data_path)
        self.gtfs_data_path = Path(gtfs_data_path)
        
        # ë„ë¡œë§ ë°ì´í„°
        self.road_nodes = None
        self.road_links = None
        
        # GTFS í•µì‹¬ ë°ì´í„° (KTDB í‘œì¤€)
        self.agency = None          # ëŒ€ì¤‘êµí†µ ê¸°ê´€ ì •ë³´
        self.stops = None           # ì •ë¥˜ì¥/ì—­ ì •ë³´  
        self.routes = None          # ë…¸ì„  ì •ë³´
        self.trips = None           # ìš´í–‰íšŒì°¨ ì •ë³´
        self.stop_times = None      # ì •ì°¨ ì‹œê°„í‘œ
        self.calendar = None        # ìš´í–‰ ì¼ì •
        
        # ì„ íƒì  GTFS ë°ì´í„°
        self.calendar_dates = None  # ì˜ˆì™¸ ìš´í–‰ì¼
        self.fare_attributes = None # ìš”ê¸ˆ ì •ë³´
        self.fare_rules = None      # ìš”ê¸ˆ ê·œì¹™
        self.shapes = None          # ë…¸ì„  í˜•ìƒ
        self.transfers = None       # í™˜ìŠ¹ ì •ë³´
        
        # í†µí•© ë¶„ì„ ë°ì´í„°
        self.integrated_stops = None
        self.route_analysis = None
        self.accessibility_matrix = None
        
        print("ğŸš€ KTDB GTFS í‘œì¤€ êµí†µ ë°ì´í„° ë¡œë” ì´ˆê¸°í™”")
        self._validate_paths()
    
    def _validate_paths(self):
        """ë°ì´í„° ê²½ë¡œ ê²€ì¦"""
        print(f"ğŸ“‚ ë„ë¡œë§ ê²½ë¡œ: {self.road_data_path}")
        print(f"ğŸ“‚ GTFS ê²½ë¡œ: {self.gtfs_data_path}")
        
        if not self.road_data_path.exists():
            print(f"âš ï¸ ë„ë¡œë§ ë°ì´í„° ê²½ë¡œ ì—†ìŒ")
            
        if not self.gtfs_data_path.exists():
            print(f"âš ï¸ GTFS ë°ì´í„° ê²½ë¡œ ì—†ìŒ")
    
    # ========== 1. GTFS í•µì‹¬ ë°ì´í„° ë¡œë”© (KTDB í‘œì¤€) ==========
    def load_gtfs_data(self) -> Dict[str, bool]:
        """KTDB GTFS í‘œì¤€ì— ë”°ë¥¸ ë°ì´í„° ë¡œë”©"""
        print("\nğŸš‡ 1ë‹¨ê³„: KTDB GTFS ë°ì´í„° ë¡œë”©...")
        
        results = {}
        
        # GTFS í•„ìˆ˜ íŒŒì¼ë“¤ (KTDB êµ¬ì¶• ì—¬ë¶€ Y)
        required_files = {
            'agency': 'agency.txt',
            'stops': 'stops.txt', 
            'routes': 'routes.txt',
            'trips': 'trips.txt',
            'stop_times': 'stop_times.txt',
            'calendar': 'calendar.txt'
        }
        
        # GTFS ì„ íƒì  íŒŒì¼ë“¤ (KTDB êµ¬ì¶• ì—¬ë¶€ N)
        optional_files = {
            'calendar_dates': 'calendar_dates.txt',
            'fare_attributes': 'fare_attributes.txt',
            'fare_rules': 'fare_rules.txt',
            'shapes': 'shapes.txt',
            'transfers': 'transfers.txt'
        }
        
        # í•„ìˆ˜ íŒŒì¼ ë¡œë”©
        print("   ğŸ“‹ í•„ìˆ˜ GTFS íŒŒì¼ ë¡œë”©:")
        for name, filename in required_files.items():
            results[name] = self._load_gtfs_file(name, filename, required=True)
        
        # ì„ íƒì  íŒŒì¼ ë¡œë”©
        print("\n   ğŸ“‹ ì„ íƒì  GTFS íŒŒì¼ ë¡œë”©:")
        for name, filename in optional_files.items():
            results[name] = self._load_gtfs_file(name, filename, required=False)
        
        # ë¡œë”© ê²°ê³¼ ìš”ì•½
        self._print_gtfs_summary(results)
        
        return results
    
    def _load_gtfs_file(self, data_name: str, filename: str, required: bool = True) -> bool:
        """ê°œë³„ GTFS íŒŒì¼ ë¡œë”©"""
        file_path = self.gtfs_data_path / filename
        
        try:
            if file_path.exists():
                # CSV ë¡œë”© (ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„)
                encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        setattr(self, data_name, df)
                        
                        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
                        if len(df) > 0:
                            status = "âœ…" if required else "ğŸ“„"
                            print(f"     {status} {filename}: {len(df):,}ê°œ ({encoding})")
                            return True
                        else:
                            print(f"     âš ï¸ {filename}: ë¹ˆ íŒŒì¼")
                            return False
                            
                    except UnicodeDecodeError:
                        continue
                        
                print(f"     âŒ {filename}: ì¸ì½”ë”© ì‹¤íŒ¨")
                return False
                
            else:
                if required:
                    print(f"     âŒ {filename}: í•„ìˆ˜ íŒŒì¼ ì—†ìŒ")
                else:
                    print(f"     â– {filename}: ì„ íƒ íŒŒì¼ ì—†ìŒ")
                return False
                
        except Exception as e:
            print(f"     âŒ {filename}: ë¡œë”© ì‹¤íŒ¨ - {str(e)[:50]}...")
            return False
    
    def _print_gtfs_summary(self, results: Dict[str, bool]):
        """GTFS ë¡œë”© ê²°ê³¼ ìš”ì•½"""
        print("\n   ğŸ“Š GTFS ë°ì´í„° ë¡œë”© ìš”ì•½:")
        
        # í•„ìˆ˜ íŒŒì¼ ì²´í¬
        required = ['agency', 'stops', 'routes', 'trips', 'stop_times', 'calendar']
        required_loaded = sum(1 for key in required if results.get(key, False))
        print(f"     í•„ìˆ˜ íŒŒì¼: {required_loaded}/{len(required)} ê°œ")
        
        # ì„ íƒì  íŒŒì¼ ì²´í¬  
        optional = ['calendar_dates', 'fare_attributes', 'fare_rules', 'shapes', 'transfers']
        optional_loaded = sum(1 for key in optional if results.get(key, False))
        print(f"     ì„ íƒ íŒŒì¼: {optional_loaded}/{len(optional)} ê°œ")
        
        # ë°ì´í„° ê·œëª¨ (ë¡œë”©ëœ ê²ƒë§Œ)
        if self.stops is not None:
            print(f"     ì •ë¥˜ì¥/ì—­: {len(self.stops):,}ê°œ")
        if self.routes is not None:
            print(f"     ë…¸ì„ : {len(self.routes):,}ê°œ")
        if self.trips is not None:
            print(f"     ìš´í–‰íšŒì°¨: {len(self.trips):,}ê°œ")
        if self.stop_times is not None:
            print(f"     ì •ì°¨ì‹œê°„: {len(self.stop_times):,}ê°œ")
    
    # ========== 2. ë„ë¡œë§ ë°ì´í„° ë¡œë”© ==========
    def load_road_network(self) -> bool:
        """ë„ë¡œë§ ë°ì´í„° ë¡œë”© (ê¸°ì¡´ ì„±ê³µ ë°©ë²• ì‚¬ìš©)"""
        print("\nğŸ›£ï¸ 2ë‹¨ê³„: ë„ë¡œë§ ë°ì´í„° ë¡œë”©...")
        
        try:
            # ë…¸ë“œ íŒŒì¼ ë¡œë”©
            node_patterns = ['ad0102*.shp', '*node*.shp', '*êµì°¨*.shp']
            node_file = self._find_file_by_patterns(self.road_data_path, node_patterns)
            
            if node_file:
                self.road_nodes = gpd.read_file(node_file, encoding='cp949')
                print(f"   âœ… ë…¸ë“œ: {len(self.road_nodes):,}ê°œ")
            
            # ë§í¬ íŒŒì¼ ë¡œë”© (ê¸°ì¡´ ì„±ê³µ ë°©ë²•)
            link_patterns = ['ad0022*.shp', '*link*.shp', '*ë„ë¡œ*.shp']
            link_file = self._find_file_by_patterns(self.road_data_path, link_patterns)
            
            if link_file:
                self.road_links = gpd.read_file(str(link_file))
                print(f"   âœ… ë§í¬: {len(self.road_links):,}ê°œ")
                
                # ë„ë¡œ ë“±ê¸‰ë³„ í†µê³„
                if 'ROAD_RANK' in self.road_links.columns:
                    self._print_road_statistics()
                
                # ì´ ë„ë¡œ ì—°ì¥
                if 'LENGTH' in self.road_links.columns:
                    total_length = self.road_links['LENGTH'].sum()
                    print(f"   ğŸ“ ì´ ë„ë¡œì—°ì¥: {total_length:,.1f} km")
            
            return self.road_nodes is not None and self.road_links is not None
            
        except Exception as e:
            print(f"âŒ ë„ë¡œë§ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def _print_road_statistics(self):
        """ë„ë¡œ ë“±ê¸‰ë³„ í†µê³„ ì¶œë ¥"""
        road_ranks = self.road_links['ROAD_RANK'].value_counts()
        print(f"   ğŸ“Š ë„ë¡œë“±ê¸‰ë³„ í†µê³„:")
        
        # KTDB ë„ë¡œë“±ê¸‰ ì½”ë“œ
        rank_names = {
            '101': 'ê³ ì†ë„ë¡œ', '102': 'ë„ì‹œê³ ì†ë„ë¡œ', '103': 'ì¼ë°˜êµ­ë„',
            '104': 'íŠ¹ë³„ê´‘ì—­ì‹œë„', '105': 'êµ­ê°€ì§€ì›ì§€ë°©ë„', 
            '106': 'ì§€ë°©ë„', '107': 'ì‹œêµ°ë„'
        }
        
        for code, count in road_ranks.head(5).items():
            name = rank_names.get(str(code), 'ê¸°íƒ€')
            print(f"     {code}({name}): {count:,}ê°œ")
    
    # ========== 3. GTFS ë°ì´í„° ë¶„ì„ ==========
    def analyze_gtfs_data(self):
        """GTFS ë°ì´í„° ìƒì„¸ ë¶„ì„"""
        print("\nğŸ“Š 3ë‹¨ê³„: GTFS ë°ì´í„° ë¶„ì„...")
        
        if not self._validate_gtfs_loaded():
            return
        
        # ê¸°ê´€ ì •ë³´ ë¶„ì„
        self._analyze_agency()
        
        # ì •ë¥˜ì¥ ë¶„ì„
        self._analyze_stops()
        
        # ë…¸ì„  ë¶„ì„  
        self._analyze_routes()
        
        # ìš´í–‰ ë¶„ì„
        self._analyze_trips()
        
        # ì‹œê°„í‘œ ë¶„ì„
        self._analyze_stop_times()
    
    def _analyze_agency(self):
        """ê¸°ê´€ ì •ë³´ ë¶„ì„"""
        if self.agency is not None:
            print("\n   ğŸ¢ ê¸°ê´€ ì •ë³´:")
            for _, agency in self.agency.iterrows():
                print(f"     ID: {agency.get('agency_id', 'N/A')}")
                print(f"     ì´ë¦„: {agency.get('agency_name', 'N/A')}")
                print(f"     URL: {agency.get('agency_url', 'N/A')}")
                print(f"     ì‹œê°„ëŒ€: {agency.get('agency_timezone', 'N/A')}")
    
    def _analyze_stops(self):
        """ì •ë¥˜ì¥ ë¶„ì„"""
        if self.stops is not None:
            print(f"\n   ğŸš ì •ë¥˜ì¥ ë¶„ì„:")
            print(f"     ì´ ì •ë¥˜ì¥: {len(self.stops):,}ê°œ")
            
            # ì¢Œí‘œ ì •ë³´ í™•ì¸
            has_coords = self.stops[['stop_lat', 'stop_lon']].notna().all(axis=1).sum()
            print(f"     ì¢Œí‘œ ìˆìŒ: {has_coords:,}ê°œ ({has_coords/len(self.stops)*100:.1f}%)")
            
            # ì¢Œí‘œ ë²”ìœ„ 
            if has_coords > 0:
                coords_df = self.stops[['stop_lat', 'stop_lon']].dropna()
                print(f"     ìœ„ë„ ë²”ìœ„: {coords_df['stop_lat'].min():.4f} ~ {coords_df['stop_lat'].max():.4f}")
                print(f"     ê²½ë„ ë²”ìœ„: {coords_df['stop_lon'].min():.4f} ~ {coords_df['stop_lon'].max():.4f}")
    
    def _analyze_routes(self):
        """ë…¸ì„  ë¶„ì„"""
        if self.routes is not None:
            print(f"\n   ğŸšŒ ë…¸ì„  ë¶„ì„:")
            print(f"     ì´ ë…¸ì„ : {len(self.routes):,}ê°œ")
            
            # ë…¸ì„  ìœ í˜•ë³„ ë¶„ì„ (KTDB ê¸°ì¤€)
            if 'route_type' in self.routes.columns:
                route_types = self.routes['route_type'].value_counts()
                print(f"     ë…¸ì„  ìœ í˜•ë³„:")
                
                # KTDB route_type ë§¤í•‘
                type_names = {
                    0: 'ì‹œë‚´/ë†ì–´ì´Œ/ë§ˆì„ë²„ìŠ¤',
                    1: 'ë„ì‹œì² ë„/ê²½ì „ì² ', 
                    2: 'í•´ìš´',
                    3: 'ì‹œì™¸ë²„ìŠ¤',
                    4: 'ì¼ë°˜ì² ë„',
                    5: 'ê³µí•­ë¦¬ë¬´ì§„ë²„ìŠ¤',
                    6: 'ê³ ì†ì² ë„',
                    7: 'í•­ê³µ'
                }
                
                for route_type, count in route_types.head(8).items():
                    name = type_names.get(route_type, f'ê¸°íƒ€({route_type})')
                    print(f"       {route_type}: {name} - {count:,}ê°œ")
    
    def _analyze_trips(self):
        """ìš´í–‰íšŒì°¨ ë¶„ì„"""
        if self.trips is not None:
            print(f"\n   ğŸšŒ ìš´í–‰ ë¶„ì„:")
            print(f"     ì´ ìš´í–‰íšŒì°¨: {len(self.trips):,}ê°œ")
            
            # ë…¸ì„ ë³„ ìš´í–‰íšŒì°¨
            if 'route_id' in self.trips.columns:
                trips_per_route = self.trips.groupby('route_id').size()
                print(f"     ë…¸ì„ ë‹¹ í‰ê·  ìš´í–‰: {trips_per_route.mean():.1f}íšŒ")
                print(f"     ìµœëŒ€ ìš´í–‰ ë…¸ì„ : {trips_per_route.max()}íšŒ")
    
    def _analyze_stop_times(self):
        """ì •ì°¨ì‹œê°„ ë¶„ì„"""
        if self.stop_times is not None:
            print(f"\n   â° ì •ì°¨ì‹œê°„ ë¶„ì„:")
            print(f"     ì´ ì •ì°¨ ê¸°ë¡: {len(self.stop_times):,}ê°œ")
            
            # ì‹œê°„ í˜•ì‹ í™•ì¸
            if 'arrival_time' in self.stop_times.columns:
                sample_times = self.stop_times['arrival_time'].dropna().head(5)
                print(f"     ì‹œê°„ í˜•ì‹ ì˜ˆì‹œ: {list(sample_times)}")
    
    # ========== 4. ë°ì´í„° í†µí•© ==========
    def integrate_transport_data(self) -> bool:
        """êµí†µ ë°ì´í„° í†µí•©"""
        print("\nğŸ”— 4ë‹¨ê³„: êµí†µ ë°ì´í„° í†µí•©...")
        
        if not self._validate_gtfs_loaded():
            print("   âš ï¸ GTFS ë°ì´í„°ê°€ ì—†ì–´ í†µí•© ë¶ˆê°€")
            return False
        
        try:
            # GTFS ì •ë¥˜ì¥ì„ ì§€ë¦¬ê³µê°„ ë°ì´í„°ë¡œ ë³€í™˜
            self._create_integrated_stops()
            
            # ë…¸ì„ -ì •ë¥˜ì¥ ì—°ê²° ë¶„ì„
            self._analyze_route_stops()
            
            # ë„ë¡œë§ê³¼ ì—°ê²° (ë„ë¡œë§ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if self.road_links is not None:
                self._link_stops_to_roads()
            
            print("   âœ… ë°ì´í„° í†µí•© ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}")
            return False
    
    def _create_integrated_stops(self):
        """GTFS ì •ë¥˜ì¥ì„ ì§€ë¦¬ê³µê°„ ë°ì´í„°ë¡œ ë³€í™˜"""
        if self.stops is None:
            return
        
        # ì¢Œí‘œê°€ ìˆëŠ” ì •ë¥˜ì¥ë§Œ ì„ íƒ
        valid_stops = self.stops.dropna(subset=['stop_lat', 'stop_lon']).copy()
        
        if len(valid_stops) > 0:
            # GeoDataFrame ìƒì„±
            self.integrated_stops = gpd.GeoDataFrame(
                valid_stops,
                geometry=gpd.points_from_xy(valid_stops.stop_lon, valid_stops.stop_lat),
                crs='EPSG:4326'
            )
            print(f"   ğŸ“ ì§€ë¦¬ê³µê°„ ì •ë¥˜ì¥: {len(self.integrated_stops):,}ê°œ")
        else:
            print(f"   âš ï¸ ì¢Œí‘œ ì •ë³´ê°€ ìˆëŠ” ì •ë¥˜ì¥ì´ ì—†ìŒ")
    
    def _analyze_route_stops(self):
        """ë…¸ì„ -ì •ë¥˜ì¥ ì—°ê²° ë¶„ì„"""
        if self.stop_times is None or self.routes is None:
            return
        
        print("   ğŸ” ë…¸ì„ -ì •ë¥˜ì¥ ì—°ê²° ë¶„ì„...")
        
        # stop_timesì—ì„œ ë…¸ì„ ë³„ ì •ë¥˜ì¥ ì¶”ì¶œ
        if 'trip_id' in self.stop_times.columns and 'route_id' in self.trips.columns:
            # trip_idë¡œ route_id ì—°ê²°
            route_stops = self.stop_times.merge(
                self.trips[['trip_id', 'route_id']], 
                on='trip_id', 
                how='left'
            )
            
            # ë…¸ì„ ë³„ ì •ë¥˜ì¥ ìˆ˜ ê³„ì‚°
            stops_per_route = route_stops.groupby('route_id')['stop_id'].nunique()
            
            print(f"     ë…¸ì„ ë‹¹ í‰ê·  ì •ë¥˜ì¥: {stops_per_route.mean():.1f}ê°œ")
            print(f"     ìµœëŒ€ ì •ë¥˜ì¥ ë…¸ì„ : {stops_per_route.max()}ê°œ")
            
            # ì •ë¥˜ì¥ë³„ ë…¸ì„  ìˆ˜ 
            routes_per_stop = route_stops.groupby('stop_id')['route_id'].nunique()
            print(f"     ì •ë¥˜ì¥ë‹¹ í‰ê·  ë…¸ì„ : {routes_per_stop.mean():.1f}ê°œ")
            
            self.route_analysis = {
                'stops_per_route': stops_per_route,
                'routes_per_stop': routes_per_stop
            }
    
    def _link_stops_to_roads(self):
        """ì •ë¥˜ì¥ê³¼ ë„ë¡œë§ ì—°ê²°"""
        if self.integrated_stops is None or self.road_links is None:
            return
        
        print("   ğŸ”— ì •ë¥˜ì¥-ë„ë¡œ ì—°ê²° ë¶„ì„...")
        
        # ì¢Œí‘œê³„ í†µì¼
        if self.integrated_stops.crs != self.road_links.crs:
            stops_projected = self.integrated_stops.to_crs(self.road_links.crs)
        else:
            stops_projected = self.integrated_stops
        
        # ìƒ˜í”Œë§ (ì„±ëŠ¥ ê³ ë ¤)
        sample_size = min(1000, len(stops_projected))
        sample_stops = stops_projected.sample(sample_size, random_state=42)
        
        # 50m ë²„í¼ë¡œ ë„ë¡œ ì—°ê²° ì°¾ê¸°
        buffered_stops = sample_stops.copy()
        buffered_stops.geometry = buffered_stops.geometry.buffer(50)
        
        try:
            # ê³µê°„ ì¡°ì¸
            stop_road_links = gpd.sjoin(
                buffered_stops,
                self.road_links,
                how='left',
                predicate='intersects'
            )
            
            connected_stops = len(stop_road_links.dropna(subset=['index_right']))
            print(f"     ë„ë¡œ ì—°ê²° ì •ë¥˜ì¥: {connected_stops}/{sample_size}ê°œ ({connected_stops/sample_size*100:.1f}%)")
            
        except Exception as e:
            print(f"     âš ï¸ ê³µê°„ ì¡°ì¸ ì‹¤íŒ¨: {str(e)[:50]}...")
    
    # ========== 5. ì§€ì—­ë³„ í•„í„°ë§ ==========
    def filter_by_region(self, region_name: str = "ê°•ë‚¨êµ¬") -> Dict:
        """ì§€ì—­ë³„ ë°ì´í„° í•„í„°ë§"""
        print(f"\nğŸ¯ 5ë‹¨ê³„: {region_name} ì§€ì—­ ë°ì´í„° ì¶”ì¶œ...")
        
        # ê°•ë‚¨êµ¬ ëŒ€ëµì  ê²½ê³„ (ë” ë„“ì€ ë²”ìœ„ë¡œ ì„¤ì •)
        if region_name == "ê°•ë‚¨êµ¬":
            bounds = {
                'min_lon': 126.95, 'max_lon': 127.15,
                'min_lat': 37.45, 'max_lat': 37.57
            }
        else:
            # ì„œìš¸ ì „ì²´ ë²”ìœ„
            bounds = {
                'min_lon': 126.7, 'max_lon': 127.3,
                'min_lat': 37.4, 'max_lat': 37.7
            }
        
        region_data = {}
        
        try:
            # GTFS ì •ë¥˜ì¥ í•„í„°ë§
            if self.integrated_stops is not None:
                region_stops = self.integrated_stops[
                    (self.integrated_stops.geometry.x >= bounds['min_lon']) &
                    (self.integrated_stops.geometry.x <= bounds['max_lon']) &
                    (self.integrated_stops.geometry.y >= bounds['min_lat']) &
                    (self.integrated_stops.geometry.y <= bounds['max_lat'])
                ]
                region_data['stops'] = region_stops
                print(f"   ğŸš {region_name} ì •ë¥˜ì¥: {len(region_stops):,}ê°œ")
                
                # í•´ë‹¹ ì§€ì—­ ë…¸ì„  ì¶”ì¶œ
                if len(region_stops) > 0 and self.stop_times is not None:
                    region_stop_ids = region_stops['stop_id'].tolist()
                    region_stop_times = self.stop_times[
                        self.stop_times['stop_id'].isin(region_stop_ids)
                    ]
                    
                    if self.trips is not None:
                        region_trip_ids = region_stop_times['trip_id'].unique()
                        region_trips = self.trips[
                            self.trips['trip_id'].isin(region_trip_ids)
                        ]
                        
                        region_route_ids = region_trips['route_id'].unique()
                        if self.routes is not None:
                            region_routes = self.routes[
                                self.routes['route_id'].isin(region_route_ids)
                            ]
                            region_data['routes'] = region_routes
                            print(f"   ğŸšŒ {region_name} ë…¸ì„ : {len(region_routes):,}ê°œ")
            
            # ë„ë¡œë§ í•„í„°ë§
            if self.road_links is not None:
                # ì¢Œí‘œê³„ ë³€í™˜
                road_links_4326 = self.road_links.to_crs('EPSG:4326')
                
                # ê²½ê³„ ë°•ìŠ¤ì™€ êµì°¨í•˜ëŠ” ë„ë¡œ
                from shapely.geometry import box
                bbox = gpd.box(bounds['min_lon'], bounds['min_lat'], 
                              bounds['max_lon'], bounds['max_lat'])
                bbox_gdf = gpd.GeoDataFrame([1], geometry=[bbox], crs='EPSG:4326')
                
                region_roads = gpd.overlay(road_links_4326, bbox_gdf, how='intersection')
                region_data['roads'] = region_roads
                
                print(f"   ğŸ›£ï¸ {region_name} ë„ë¡œ: {len(region_roads):,}ê°œ")
                
                if 'LENGTH' in region_roads.columns and len(region_roads) > 0:
                    region_road_length = region_roads['LENGTH'].sum()
                    print(f"   ğŸ“ {region_name} ë„ë¡œì—°ì¥: {region_road_length:.1f} km")
            
            return region_data
            
        except Exception as e:
            print(f"âŒ ì§€ì—­ í•„í„°ë§ ì‹¤íŒ¨: {e}")
            return {}
    
    # ========== 6. ê²°ê³¼ ì €ì¥ ë° ìš”ì•½ ==========
    def get_comprehensive_summary(self) -> Dict:
        """ì¢…í•© ë°ì´í„° ìš”ì•½"""
        summary = {
            'gtfs_data': {
                'agency': len(self.agency) if self.agency is not None else 0,
                'stops': len(self.stops) if self.stops is not None else 0,
                'routes': len(self.routes) if self.routes is not None else 0,
                'trips': len(self.trips) if self.trips is not None else 0,
                'stop_times': len(self.stop_times) if self.stop_times is not None else 0,
                'calendar': len(self.calendar) if self.calendar is not None else 0
            },
            'road_network': {
                'nodes': len(self.road_nodes) if self.road_nodes is not None else 0,
                'links': len(self.road_links) if self.road_links is not None else 0,
                'total_length_km': self.road_links['LENGTH'].sum() if self.road_links is not None and 'LENGTH' in self.road_links.columns else 0
            },
            'integration': {
                'integrated_stops': len(self.integrated_stops) if self.integrated_stops is not None else 0,
                'has_route_analysis': self.route_analysis is not None
            }
        }
        return summary
    
    def save_data(self, output_dir: str):
        """ë°ì´í„° ì €ì¥"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥: {output_dir}/")
        
        try:
            # GTFS ë°ì´í„° ì €ì¥
            gtfs_files = ['agency', 'stops', 'routes', 'trips', 'stop_times', 'calendar']
            for file_name in gtfs_files:
                data = getattr(self, file_name)
                if data is not None:
                    data.to_csv(output_path / f"{file_name}.csv", index=False, encoding='utf-8')
                    print(f"   âœ… {file_name}.csv")
            
            # í†µí•© ì •ë¥˜ì¥ ì €ì¥ (ì§€ë¦¬ê³µê°„ ë°ì´í„°)
            if self.integrated_stops is not None:
                self.integrated_stops.to_file(output_path / "integrated_stops.shp", encoding='utf-8')
                print(f"   âœ… integrated_stops.shp")
            
            # ìš”ì•½ ì •ë³´ ì €ì¥
            summary = self.get_comprehensive_summary()
            import json
            with open(output_path / "summary.json", 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            print(f"   âœ… summary.json")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # ========== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ==========
    def _find_file_by_patterns(self, directory: Path, patterns: List[str]) -> Optional[Path]:
        """íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°"""
        for pattern in patterns:
            files = list(directory.glob(pattern))
            if files:
                return files[0]
        return None
    
    def _validate_gtfs_loaded(self) -> bool:
        """GTFS í•µì‹¬ ë°ì´í„° ë¡œë”© í™•ì¸"""
        required = [self.stops, self.routes, self.trips, self.stop_times]
        loaded_count = sum(1 for data in required if data is not None)
        return loaded_count >= 2  # ìµœì†Œ 2ê°œ ì´ìƒì˜ í•µì‹¬ ë°ì´í„° í•„ìš”


# ========== ë©”ì¸ ì‹¤í–‰ ì½”ë“œ ==========
if __name__ == "__main__":
    print("ğŸš€ KTDB GTFS í‘œì¤€ êµí†µ ë°ì´í„° ë¡œë” ì‹œì‘")
    print("=" * 70)
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì • - ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
    road_data_path = "C:\\Users\\sec\\Desktop\\kim\\í•™íšŒ\\GTFS\\code\\road_data"
    gtfs_data_path = "C:\\Users\\sec\\Desktop\\kim\\í•™íšŒ\\GTFS\\code\\202303_GTFS_DataSet"
    
    try:
        # ë¡œë” ìƒì„±
        loader = KTDBGTFSLoader(road_data_path, gtfs_data_path)
        
        # 1ë‹¨ê³„: GTFS ë°ì´í„° ë¡œë”©
        gtfs_results = loader.load_gtfs_data()
        
        # 2ë‹¨ê³„: ë„ë¡œë§ ë°ì´í„° ë¡œë”©  
        road_success = loader.load_road_network()
        
        # 3ë‹¨ê³„: GTFS ë°ì´í„° ë¶„ì„
        loader.analyze_gtfs_data()
        
        # 4ë‹¨ê³„: ë°ì´í„° í†µí•©
        integration_success = loader.integrate_transport_data()
        
        # 5ë‹¨ê³„: ê°•ë‚¨êµ¬ ì§€ì—­ ë°ì´í„° ì¶”ì¶œ
        gangnam_data = loader.filter_by_region("ê°•ë‚¨êµ¬")
        
        # 6ë‹¨ê³„: ê²°ê³¼ ìš”ì•½ ë° ì €ì¥
        print("\n" + "=" * 70)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        
        summary = loader.get_comprehensive_summary()
        
        # GTFS ë°ì´í„° ìš”ì•½
        print(f"\nğŸš‡ GTFS ë°ì´í„°:")
        gtfs_summary = summary['gtfs_data']
        print(f"   ê¸°ê´€(agency): {gtfs_summary['agency']:,}ê°œ")
        print(f"   ì •ë¥˜ì¥(stops): {gtfs_summary['stops']:,}ê°œ")
        print(f"   ë…¸ì„ (routes): {gtfs_summary['routes']:,}ê°œ") 
        print(f"   ìš´í–‰(trips): {gtfs_summary['trips']:,}ê°œ")
        print(f"   ì •ì°¨ì‹œê°„(stop_times): {gtfs_summary['stop_times']:,}ê°œ")
        print(f"   ë‹¬ë ¥(calendar): {gtfs_summary['calendar']:,}ê°œ")
        
        # ë„ë¡œë§ ë°ì´í„° ìš”ì•½
        print(f"\nğŸ›£ï¸ ë„ë¡œë§ ë°ì´í„°:")
        road_summary = summary['road_network']
        print(f"   ë…¸ë“œ: {road_summary['nodes']:,}ê°œ")
        print(f"   ë§í¬: {road_summary['links']:,}ê°œ")
        print(f"   ì´ ì—°ì¥: {road_summary['total_length_km']:,.1f} km")
        
        # í†µí•© ë°ì´í„° ìš”ì•½
        print(f"\nğŸ”— í†µí•© ë°ì´í„°:")
        integration_summary = summary['integration']
        print(f"   ì§€ë¦¬ê³µê°„ ì •ë¥˜ì¥: {integration_summary['integrated_stops']:,}ê°œ")
        print(f"   ë…¸ì„  ë¶„ì„: {'âœ…' if integration_summary['has_route_analysis'] else 'âŒ'}")
        
        # ê°•ë‚¨êµ¬ ë°ì´í„° ìš”ì•½
        if gangnam_data:
            print(f"\nğŸ¯ ê°•ë‚¨êµ¬ ë°ì´í„°:")
            if 'stops' in gangnam_data:
                print(f"   ì •ë¥˜ì¥: {len(gangnam_data['stops']):,}ê°œ")
            if 'routes' in gangnam_data:
                print(f"   ë…¸ì„ : {len(gangnam_data['routes']):,}ê°œ")
            if 'roads' in gangnam_data:
                print(f"   ë„ë¡œ: {len(gangnam_data['roads']):,}ê°œ")
        
        # ë°ì´í„° í’ˆì§ˆ í‰ê°€
        print(f"\nğŸ¯ ë°ì´í„° í’ˆì§ˆ í‰ê°€:")
        gtfs_quality = "ìš°ìˆ˜" if gtfs_summary['stops'] > 1000 and gtfs_summary['routes'] > 10 else "ë³´í†µ"
        road_quality = "ìš°ìˆ˜" if road_summary['links'] > 10000 else "ë³´í†µ"
        integration_quality = "ì„±ê³µ" if integration_summary['integrated_stops'] > 100 else "ì œí•œì "
        
        print(f"   GTFS ë°ì´í„°: {gtfs_quality}")
        print(f"   ë„ë¡œë§ ë°ì´í„°: {road_quality}")
        print(f"   ë°ì´í„° í†µí•©: {integration_quality}")
        
        # ë°ì´í„° ì €ì¥
        output_dir = "output_integrated_transport_data"
        loader.save_data(output_dir)
        
        # Multi-modal RAPTOR ì¤€ë¹„ë„ í‰ê°€
        print(f"\nğŸš€ Multi-modal RAPTOR ì¤€ë¹„ë„:")
        
        raptor_ready = False
        if gtfs_summary['stops'] > 0 and gtfs_summary['routes'] > 0 and gtfs_summary['stop_times'] > 0:
            print(f"   âœ… GTFS ê¸°ë°˜ ëŒ€ì¤‘êµí†µ ë¼ìš°íŒ… ê°€ëŠ¥")
            raptor_ready = True
        else:
            print(f"   âŒ GTFS ë°ì´í„° ë¶€ì¡±")
        
        if road_summary['links'] > 0:
            print(f"   âœ… ë„ë¡œë§ ê¸°ë°˜ ê²½ë¡œ íƒìƒ‰ ê°€ëŠ¥")
        else:
            print(f"   âŒ ë„ë¡œë§ ë°ì´í„° ì—†ìŒ")
        
        if integration_summary['integrated_stops'] > 0:
            print(f"   âœ… ì§€ë¦¬ê³µê°„ ë¶„ì„ ê°€ëŠ¥")
        else:
            print(f"   âŒ ì¢Œí‘œ ì •ë³´ ë¶€ì¡±")
        
        if raptor_ready:
            print(f"\nğŸ‰ Python Multi-modal RAPTOR êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ!")
            print(f"   ğŸ“ ì—°êµ¬ ì§€ì—­: ê°•ë‚¨êµ¬")
            print(f"   ğŸš‡ ëŒ€ì¤‘êµí†µ: GTFS í‘œì¤€ ë°ì´í„°")
            print(f"   ğŸ›£ï¸ ë„ë¡œë§: ì „êµ­ í‘œì¤€ ë°ì´í„°")
            print(f"   ğŸ’¾ í†µí•© ë°ì´í„°: {output_dir}/ ì €ì¥ë¨")
            
            
        else:
            print(f"\nâš ï¸ ì¼ë¶€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì œí•œì  ë¶„ì„ë§Œ ê°€ëŠ¥")
        
        print(f"\n" + "=" * 70)
        print("ğŸ¯ KTDB GTFS í‘œì¤€ êµí†µ ë°ì´í„° ë¡œë” ì™„ë£Œ!")
        print("=" * 70)
        
    except KeyboardInterrupt:
        print(f"\nâŒ ì‚¬ìš©ìì— ì˜í•œ ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()